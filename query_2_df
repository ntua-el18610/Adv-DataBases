from pyspark.sql import SparkSession
import time
from pyspark.sql.functions import col, when, count, trim, year, to_date, desc
from pyspark.sql.window import Window
from pyspark.sql.functions import dense_rank

# Initialize SparkSession
spark = SparkSession.builder.appName("Crime Analysis by Area").getOrCreate()

# Start timing
start_time = time.time()

# Load the data into DataFrames
df_victims19 = spark.read.csv(
    "s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv",
    header=True,
    inferSchema=True,
    multiLine=True,
    quote='"',
    escape='"'
)
df_victims_current = spark.read.csv(
    "s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv",
    header=True,
    inferSchema=True,
    multiLine=True,
    quote='"',
    escape='"'
)

# Combine the two datasets
df_all_victims = df_victims19.union(df_victims_current)

# Trim all column names to handle trailing spaces
df_all_victims = df_all_victims.select([col(c).alias(c.strip()) for c in df_all_victims.columns])

# Ensure the "AREA" column is treated as an integer (if necessary)
df_all_victims = df_all_victims.withColumn("AREA NAME", trim(col("AREA NAME")).cast("string"))

# Filter valid rows (ensure AREA is not null)
df_all_victims = df_all_victims.filter(col("AREA NAME").isNotNull())

# Convert "DATE OCC" to date format and extract the year
df_all_victims = df_all_victims.withColumn(
    "Year",
    year(to_date(col("DATE OCC"), "MM/dd/yyyy hh:mm:ss a"))
)

# Calculate percentage for each area
result = (
    df_all_victims.groupBy("AREA NAME", "Year")
    .agg(
        count("*").alias("Total_Count"),
        count(when(~col("Status Desc").isin("UNK", "Invest Cont"), 1)).alias("Valid_Count")
    )
    .withColumn("Percentage", (col("Valid_Count") / col("Total_Count")) * 100)
)

# Define a window specification for ranking within each year
window_spec = Window.partitionBy("Year").orderBy(desc("Percentage"))

# Add ranking column
ranked_result = result.withColumn("Ranking", dense_rank().over(window_spec))

# Filter top 3 areas per year
top_3_per_year = ranked_result.filter(col("Ranking") <= 3)

# Select and order the final result
final_result = top_3_per_year.select("Year", "AREA NAME", "Percentage", "Ranking").orderBy("Year", "Ranking")

# Show the results
final_result.show(truncate=False)

# Stop timing and print execution time
end_time = time.time()
elapsed_time = end_time - start_time
print(f"Time taken: {elapsed_time:.2f} seconds")
